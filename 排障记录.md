# FoundationStereo 排障记录（2026-02-25）

本文档记录本次在 `FoundationStereo` 项目中从环境搭建到 `run_demo.py` 成功运行的完整排障过程，便于后续复用。

## 1. 目标

- 在本机（RTX 5080）上跑通 `scripts/run_demo.py`
- 使用本地权重 `./pretrained_models/23-51-11/model_best_bp2.pth`
- 成功产出视差可视化和点云输出

## 2. 关键环境背景

- 系统：Linux
- GPU：NVIDIA GeForce RTX 5080（`sm_120`）
- 初始环境文件：`environment.yml`（内含 `torch==2.4.1`、`xformers==0.0.28.post1`）

## 3. 遇到的问题与修复

### 问题 A：`flash-attn` 安装失败（初次）

- **现象**
  - `pip install flash-attn` 报错：`ModuleNotFoundError: No module named 'torch'`
- **根因**
  - 构建隔离环境（build isolation）内没有可见 `torch`
- **处理**
  - 改为：`pip install flash-attn --no-build-isolation`

---

### 问题 B：GPU 架构与 PyTorch 不兼容

- **现象**
  - 运行时出现警告：当前 PyTorch 仅支持到 `sm_90`，不支持 `sm_120`
- **根因**
  - 旧版 `torch==2.4.1+cu121` 不支持 50 系列新架构
- **处理**
  - 升级到支持新卡的 PyTorch CUDA 版本（`cu128/cu130` 路线）
  - 同时移除强绑定旧 torch 的包（如旧 `xformers`）

---

### 问题 C：`xformers` 与新 torch 版本冲突

- **现象**
  - 提示：`xformers 0.0.28.post1 requires torch==2.4.1`
- **根因**
  - 依赖约束固定到旧 torch
- **处理**
  - 先卸载：`xformers`
  - 以“先跑通 demo”为目标，允许无 `xformers` 运行（仅有 warning）

---

### 问题 D：`flash-attn` 构建卡住/失败（CUDA 版本不一致）

- **现象**
  - 构建阶段长时间停滞
  - 失败信息：`The detected CUDA version (13.0) mismatches ... PyTorch (12.6)`
- **根因**
  - 编译器 `nvcc` 与 PyTorch 所用 CUDA 主版本不一致
- **处理**
  - 当前采取“先跳过 flash-attn，优先跑通 demo”
  - 如需继续安装，需先对齐 `nvcc` 与 `torch.version.cuda`

---

### 问题 E：离线环境导致在线下载失败（Hugging Face）

- **现象**
  - `Network is unreachable`，在 `timm.create_model(..., pretrained=True)` 处报错
- **根因**
  - 代码默认尝试从 Hugging Face 下载 EdgeNeXt 预训练权重
- **修复（代码已改）**
  - 文件：`core/extractor.py`
  - 改动：`pretrained=True` -> `pretrained=False`
  - 备注：代码中已加入 `[Modified by Assistant]` 注释

---

### 问题 F：离线环境导致在线下载失败（torch.hub / DINOv2）

- **现象**
  - `torch.hub.load('facebookresearch/dinov2', ...)` 因无网络超时
- **根因**
  - 默认从 GitHub 在线拉取 DINOv2 hub 仓库
- **修复（代码已改）**
  - 文件：`depth_anything/dpt.py`
  - 改动：改为 `source='local'` 从仓库内 `../dinov2` 本地加载，并设置 `pretrained=False`
  - 备注：代码中已加入 `[Modified by Assistant]` 注释

---

### 问题 G：PyTorch 2.6+ 的 `torch.load` 默认行为变化

- **现象**
  - `_pickle.UnpicklingError: Weights only load failed`
- **根因**
  - 新版本默认 `weights_only=True`，而 checkpoint 内含额外对象
- **修复（代码已改）**
  - 文件：`scripts/run_demo.py`
  - 改动：`torch.load(ckpt_dir)` -> `torch.load(ckpt_dir, map_location='cpu', weights_only=False)`
  - 备注：代码中已加入 `[Modified by Assistant]` 注释

## 4. 最终运行结果

最终 `run_demo.py` 成功执行，日志关键点如下：

- `ckpt global_step:200000, epoch:40`
- `Output saved to ./test_outputs`
- `PCL saved to ./test_outputs`
- 打开点云可视化窗口（`Visualizing point cloud. Press ESC to exit.`）

输出文件：

- `test_outputs/vis.png`
- `test_outputs/depth_meter.npy`
- `test_outputs/cloud.ply`
- （可选）`test_outputs/cloud_denoise.ply`

## 5. 本次代码改动清单

- `core/extractor.py`
  - 禁止在线下载 `timm` 预训练权重（离线可跑）
- `depth_anything/dpt.py`
  - DINOv2 改为本地 hub 加载，禁止在线拉取
- `scripts/run_demo.py`
  - `torch.load` 适配 PyTorch 新默认行为

## 6. 仍存在但不阻塞运行的提示

- `imageio` v3 的弃用警告（DeprecationWarning）
- `torch.cuda.amp.autocast` 的 FutureWarning（建议后续改为 `torch.amp.autocast('cuda', ...)`）
- `xformers is not available`（当前可运行，仅可能影响性能或特定路径）

## 7. 建议的后续优化（可选）

- 统一升级代码中的 AMP 调用写法，清理 FutureWarning
- 将离线模式做成配置开关（例如 `--offline 1`），减少手改代码
- 将本次修复整理进 README（“离线部署”章节）

